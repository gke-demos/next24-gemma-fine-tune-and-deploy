apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: langserve-gemma
  labels:
    cloud.googleapis.com/location: us-central1
  annotations:
    run.googleapis.com/ingress: all
    run.googleapis.com/ingress-status: all
    run.googleapis.com/launch-stage: BETA
spec:
  template:
    metadata:
      annotations:
        run.googleapis.com/network-interfaces: '[{"network":"default","subnetwork":"default"}]'
        run.googleapis.com/vpc-access-egress: private-ranges-only
        run.googleapis.com/execution-environment: gen2
        autoscaling.knative.dev/maxScale: '100'
        run.googleapis.com/startup-cpu-boost: 'true'
    spec:
      containerConcurrency: 80
      timeoutSeconds: 300
      containers:
      - name: langserve-gemma
        image: 'us-docker.pkg.dev/llm-showcase-414410/langserve/langserve-tgi:v1.0.2'
        ports:
        - name: http1
          containerPort: 8080
        env:
        - name: MODEL_SERVER
          value: 'http://llm-service.internal.gke.ninja:8000'
        - name: MODEL
          value: gemma
        resources:
          limits:
            cpu: 1000m
            memory: 512Mi
        startupProbe:
          timeoutSeconds: 240
          periodSeconds: 240
          failureThreshold: 1
          tcpSocket:
            port: 8080
  traffic:
  - percent: 100
    latestRevision: true
